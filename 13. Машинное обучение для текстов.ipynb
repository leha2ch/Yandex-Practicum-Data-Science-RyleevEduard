{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импотр библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    import spacy\n",
    "except:\n",
    "    !pip install spacy -q\n",
    "    import spacy\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv', usecols=[1, 2])\n",
    "\n",
    "display(df.head(10))\n",
    "print('----------\\nИнформация о таблице:\\n')\n",
    "df.info()\n",
    "print(f'----------\\nДубликатов в таблице: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация, удаление стоп слов, лематизация, удаление строк разделителей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stopwords_english = set(stopwords.words('english'))\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def f_preparation(text):\n",
    "    # в нижний регистр\n",
    "    text = text.lower()\n",
    "    # только текст\n",
    "    text = re.sub(r'[^a-z]', ' ', text)\n",
    "    # удаление повторных пробелов\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # деление текста на токены\n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "df['lemmatize_text'] = df['text'].apply(f_preparation)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n' \n",
    "\n",
    "def f_lemmatize_sent(text): \n",
    "    # Вводимый текст представляет собой строку, возвращающую строки в нижнем регистре.\n",
    "    text = [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) for word, tag in pos_tag(nltk.word_tokenize(text))]\n",
    "    # удаление стоп слов\n",
    "    text = [word for word in text if word not in stopwords_english]\n",
    "    return ' '.join(text)\n",
    "     \n",
    "df['lemmatize_text'] = df['lemmatize_text'].apply(f_lemmatize_sent)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_conti_rep_char(str1):\n",
    "    tchr = str1.group(0)\n",
    "    if len(tchr) > 1:\n",
    "      return tchr[0:1]\n",
    "\n",
    "def f_check_unique_char(rep, sent_text):\n",
    "    # регулярное выражение для повторяющихся символов\n",
    "    convert = re.sub(r'(\\w)\\1+', rep, sent_text)\n",
    "    # возврат конвертированного слова\n",
    "    return convert\n",
    " \n",
    "df['lemmatize_text'] = df['lemmatize_text'].apply(lambda x : f_check_unique_char(f_conti_rep_char, x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка разделения по классам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['toxic'].value_counts().plot.bar()\n",
    "plt.title('Соотношение токсичности комментариев')\n",
    "plt.xlabel('Доля комментраиев \"1 = токсичный\"', fontsize=10, color='blue')\n",
    "plt.ylabel(\"Количество коментариев\", fontsize=10, color='orange')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы по этапу предварительной обработки информации**\n",
    "\n",
    "В ходе реализации подготовительного этапа были выполнены следующие операции:\n",
    "- Интеграция программных инструментов: осуществлён процесс подключения необходимых библиотек и модулей\n",
    "- Загрузка информационных массивов: выполнен импорт исходных данных для последующей обработки\n",
    "- Комплексная очистка данных: реализован многоступенчатый процесс подготовки информации, включающий:\n",
    "    - Нормализация текста: приведение всех текстовых элементов к единому регистру\n",
    "    - Фильтрация контента: удаление неалфавитных символов и специальных знаков\n",
    "    - Морфологический анализ: разбивка текстовых последовательностей на составные элементы\n",
    "    - Лемматизация: приведение слов к исходной форме\n",
    "    - Семантическая очистка: исключение служебных слов и стоп-символов\n",
    "- Статистический анализ: проведено исследование распределения показателей токсичности по категориям\n",
    "\n",
    "По завершении подготовительного этапа формируется база для перехода к следующему этапу работы — построению и обучению аналитических моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для отбора лучшей модели сократим выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.sample(n=10000, random_state=42).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "# инициализация TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = data['lemmatize_text']\n",
    "y = data['toxic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify = y)\n",
    "round(X_train.shape[0]/X.shape[0], 2), round(X_test.shape[0]/X.shape[0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим общий `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_training(model, params):\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('model', model)])\n",
    "    grid = GridSearchCV(pipeline, cv = 5, n_jobs = -1, param_grid = params ,scoring = 'f1', verbose = False)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f'Значение \"F1-score\" на кросс-валидации: {grid.best_score_:.3}\\n----------')\n",
    "    print(f'Параметры лучшей модели: {grid.best_params_}\\n----------')\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим `LogisticRegression()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_mod = f_training(LogisticRegression(random_state=RANDOM_STATE), \n",
    "                    {\n",
    "                     'model__C':[0.1, 1.0, 10.0], \n",
    "                     'model__penalty':[\"l1\", \"l2\", \"elasticnet\", None]\n",
    "                    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим `SVC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svc_mod = f_training(SVC(kernel='linear', \n",
    "                     random_state=RANDOM_STATE),\n",
    "                     {\n",
    "                      'model__degree':[3, 4]\n",
    "                     }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим `DecisionTreeClassifier()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtc_mod = f_training(DecisionTreeClassifier(criterion='gini', random_state=RANDOM_STATE),\n",
    "                     {\n",
    "                      'model__max_depth':[None, 2,4,8]\n",
    "                     }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим `LGBMClassifier()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lgbm_mod = f_training(LGBMClassifier(learning_rate=0.1, \n",
    "                                     n_estimators=200, \n",
    "                                     random_state=RANDOM_STATE,\n",
    "                                     n_jobs=1,\n",
    "                                     verbose=-1), \n",
    "                                     {\n",
    "                                      'model__max_depth': [None, 8]\n",
    "                                     }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составим сводную таблицу по обученным моделям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отберем модель с максимальным значением `F1-score` на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'Model': ['LogisticRegression', 'SVC', 'DecisionTreeClassifier', 'LGBMClassifier'],\n",
    "                        'f1_score': [lr_mod.best_score_, svc_mod.best_score_, dtc_mod.best_score_, lgbm_mod.best_score_]\n",
    "                      })\n",
    "results = results.sort_values('f1_score', ascending=False).reset_index(drop=True).head(1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переобучим выбранную модель на полных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['lemmatize_text']\n",
    "y = df['toxic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify = y)\n",
    "round(X_train.shape[0]/X.shape[0], 2), round(X_test.shape[0]/X.shape[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_mod = f_training(LogisticRegression(random_state=RANDOM_STATE), \n",
    "                    {\n",
    "                     'model__C':[0.1, 1.0, 10.0], \n",
    "                     'model__penalty':[\"l1\", \"l2\", \"elasticnet\", None]\n",
    "                    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расчитаем `F1-score` на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В соответствии с условием задачи её значение должно быть не меньше 0,75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Метрика F1-score \"LogisticRegression\" на тестовой выборке: {lr_mod.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим лучшую модель на адекватность моделью `DummyClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy='stratified', random_state=RANDOM_STATE).fit(X_train, y_train)\n",
    "\n",
    "print(f'Метрика F1-score \"DummyClassifier\" на тестовой выборке: {f1_score(y_test, dummy_clf.predict(X_test)):.3f}')\n",
    "print(f'Значение F1-score \"LogisticRegression\" на тестовой выборке лучше \"DummyClassifier\" в: {lr_mod.score(X_test, y_test) / f1_score(y_test, dummy_clf.predict(X_test)) :.3f} раз')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Полученные показатели валидации разработанного алгоритма на проверочной подвыборке демонстрируют превосходство над базовым решением, построенным на константных значениях. Таким образом, осуществлённая исследовательская работа и реализованные технические решения позволили достичь поставленных целей проекта и получить значимый практический результат.\n",
    "\n",
    "Успешное превышение метрик по сравнению с тривиальной моделью подтверждает эффективность выбранных методологических подходов и корректность проведённой оптимизации параметров системы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе реализации исследовательского проекта были последовательно выполнены следующие этапы:\n",
    "\n",
    "- **Предварительная обработка массива данных**, включающая:\n",
    "    - Унификацию регистра текстовых элементов\n",
    "    - Фильтрацию символьного состава с сохранением исключительно буквенных значений\n",
    "    - Выполнение процедуры токенизации\n",
    "    - Приведение лексем к базовой форме (лемматизация)\n",
    "    - Элиминацию стоп-слов\n",
    "    - Исследование распределения показателей токсичности по категориальным признакам\n",
    "\n",
    "- **Стратификация датасета**: осуществлено разделение информационного массива на подмножества для обучения и валидации. С целью оптимизации процесса поиска оптимальной конфигурации произведено случайное сокращение объёма выборки до 10 000 записей.\n",
    "\n",
    "- **Имплементация алгоритмов классификации**:\n",
    "    - Логистическая регрессия (`LogisticRegression`)\n",
    "    - Метод опорных векторов (`SVC`)\n",
    "    - Деревья решений (`DecisionTreeClassifier`)\n",
    "    - Градиентный бустинг (`LGBMClassifier`)\n",
    "\n",
    "- **Оценка эффективности**: на основе метрики F1-score (комплексный показатель качества для задач классификации, рассчитываемый как гармоническое среднее точности и полноты) была идентифицирована оптимальная модель — `LogisticRegression`.\n",
    "\n",
    "- **Финальная валидация**: после переобучения выбранной модели на полном обучающем наборе получены следующие результаты:\n",
    "    - Значение F1-score для `LogisticRegression` при кросс-валидации: 0.76 (превышает целевой показатель 0.75)\n",
    "    - Значение F1-score для `LogisticRegression` на валидационной выборке: 0.76 (превышает целевой показатель 0.75)\n",
    "\n",
    "- **Верификация результатов**: проведено сопоставление расчётных метрик с целевым значением F1-score (не менее 0.75)\n",
    "\n",
    "- **Проверка адекватности**: выполнена валидация оптимальной модели посредством сравнения с базовой моделью DummyClassifier\n",
    "\n",
    "**Заключение**\n",
    "\n",
    "Для интернет-магазин «Викишоп» разработан инструмент, который будет искать токсичные комментарии и отправлять их на модерацию, при этом значение качества модели превышает установленный минимальный уровень в 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 6526,
    "start_time": "2025-08-15T20:09:10.074Z"
   },
   {
    "duration": 4476,
    "start_time": "2025-08-15T20:09:44.305Z"
   },
   {
    "duration": 1092,
    "start_time": "2025-08-15T20:11:51.299Z"
   },
   {
    "duration": 49014,
    "start_time": "2025-08-15T20:14:46.070Z"
   },
   {
    "duration": 495361,
    "start_time": "2025-08-15T20:15:35.085Z"
   },
   {
    "duration": 2301,
    "start_time": "2025-08-15T20:23:50.448Z"
   },
   {
    "duration": 10939,
    "start_time": "2025-08-20T04:58:33.442Z"
   },
   {
    "duration": 512292,
    "start_time": "2025-08-20T04:59:45.746Z"
   },
   {
    "duration": 2299,
    "start_time": "2025-08-20T05:08:18.040Z"
   },
   {
    "duration": 138,
    "start_time": "2025-08-20T05:08:20.340Z"
   },
   {
    "duration": 25,
    "start_time": "2025-08-20T05:08:20.480Z"
   },
   {
    "duration": 45,
    "start_time": "2025-08-20T05:08:20.506Z"
   },
   {
    "duration": 113,
    "start_time": "2025-08-20T05:08:20.554Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
